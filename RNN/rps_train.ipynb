{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import seaborn as sb\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "with open(\"Rock_Paper_Scissors_Raw.csv\", encoding=\"utf-8\") as f:\n",
    "    f.readline() # header\n",
    "    for line in f:\n",
    "        raw_data.append([int(c) for c in line.split(\",\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data = []\n",
    "current_game_id = None\n",
    "current_game = []\n",
    "\n",
    "for r in raw_data:\n",
    "    if r[2] == 0 or r[3] ==0:\n",
    "        continue\n",
    "    if current_game_id != r[0]:\n",
    "        game_data.append(current_game)\n",
    "        current_game_id = r[0]\n",
    "        current_game = []\n",
    "    current_game.append((r[2], r[3]))\n",
    "\n",
    "game_data = game_data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data_simulated = []\n",
    "r_move = lambda : random.choice((1,2,3))\n",
    "\n",
    "# length=1 (constant)\n",
    "game_data_simulated += [[(move, r_move()) for i in range(random.randint(6,20))]\n",
    "                        for move in (1,2,3) for i_g in range(1000)]\n",
    "\n",
    "# length=2 (alternating)\n",
    "game_data_simulated += [sum(([(move1, r_move()), (move2, r_move())] for i in range(random.randint(4,10))), [])\n",
    "                        for move1 in (1,2,3) for move2 in (1,2,3) for i_g in range(500)]\n",
    "\n",
    "# length=3 \n",
    "game_data_simulated += [sum(([(move1, r_move()), (move2, r_move()), (move3, r_move())]\n",
    "                             for i in range(random.randint(4,7))), [])\n",
    "                        for move1 in (1,2,3) for move2 in (1,2,3) for move3 in (1,2,3) for i_g in range(150)]\n",
    "\n",
    "# length=4\n",
    "game_data_simulated += [sum(([(move1, r_move()), (move2, r_move()), (move3, r_move()), (move4, r_move())]\n",
    "                             for i in range(random.randint(3,5))), [])\n",
    "                        for move1 in (1,2,3) for move2 in (1,2,3) for move3 in (1,2,3) for move4 in (1,2,3) \n",
    "                        for i_g in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_game(game, invert=False):\n",
    "    game_enc = []\n",
    "    # we add a zero input to the beginning\n",
    "    # as the model should be able to predict the first move\n",
    "    game_enc.append([0] * 6)\n",
    "    for p1, p2 in game:\n",
    "        if invert:\n",
    "            p1, p2 = p2, p1\n",
    "        game_enc.append([0] * 6)\n",
    "        game_enc[-1][p1 - 1] = 1\n",
    "        game_enc[-1][p2 - 1 + 3] = 1\n",
    "    return game_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data_one_hot = []\n",
    "for game in game_data:\n",
    "    # for real games we can use both players to train\n",
    "    for invert in (True, False):\n",
    "        game_data_one_hot.append(enc_game(game, invert=invert))\n",
    "for game in game_data_simulated:\n",
    "    # for simulated games we don't train on the player playing randomly\n",
    "    game_data_one_hot.append(enc_game(game))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\paul\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# for batchsize=1 training\n",
    "# training with batchsize 1 is very slow but the resulting models at least make sense\n",
    "\n",
    "X = [game[:-1] for game in game_data_one_hot]\n",
    "Y = [[move[:3] for move in game[1:]] for game in game_data_one_hot]\n",
    "X_np = [np.array(x).astype(np.float32) for x in X]\n",
    "Y_np = [np.array(y).astype(np.float32) for y in Y]\n",
    "dataset = tf.data.Dataset.from_generator(lambda: zip(X_np, Y_np), output_types=(tf.dtypes.float32, tf.dtypes.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 2000\n",
    "dev_size = 2000\n",
    "dataset = dataset.shuffle(100000)\n",
    "test_dataset = dataset.take(test_size)\n",
    "dev_dataset = dataset.skip(test_size).take(dev_size)\n",
    "train_dataset = dataset.skip(test_size + dev_size)\n",
    "train_size = len(X) - test_size - dev_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I tried various ways to get training with batch_size > 1 to work (see rps_experiments.ipynb) \n",
    "# but there was always some kind of problem.\n",
    "# Just padding gave bad results (maybe because the average game length is far below the maximum), and the\n",
    "# networks trained with masking behaved very weirdly, giving exploding probabilities after a few moves.\n",
    "# Thankfully the networks and dataset are small enough that training with batch_size=1 doesn't take too long (<24h).\n",
    "batch_size = 1\n",
    "train_dataset_batched = train_dataset.batch(batch_size, drop_remainder=True).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deep_model(state_dims, batch_size, stateful=False):\n",
    "    return tf.keras.Sequential([\n",
    "        #tf.keras.layers.Masking(mask_value=-1.0, batch_input_shape=[batch_size, None, 6]),\n",
    "        tf.keras.layers.SimpleRNN(state_dims[0], batch_input_shape=[batch_size, None, 6],\n",
    "                                 return_sequences=True,  stateful=stateful, activation=\"softsign\"),\n",
    "    ] + [tf.keras.layers.SimpleRNN(s, return_sequences=True, stateful=stateful, activation=\"softsign\") \n",
    "         for s in state_dims[1:]\n",
    "        ] + [\n",
    "        tf.keras.layers.Dense(3),\n",
    "        tf.keras.layers.Softmax()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_3l = build_deep_model([10,10,10], 1)\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001)\n",
    "deep_model_3l.compile(opt, loss=tf.keras.losses.categorical_crossentropy,metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "182732/182732 [==============================] - 1717s 9ms/step - loss: 1.0613 - acc: 0.4549\n",
      "Epoch 2/10\n",
      "182732/182732 [==============================] - 1716s 9ms/step - loss: 1.0518 - acc: 0.4644\n",
      "Epoch 3/10\n",
      "182732/182732 [==============================] - 1720s 9ms/step - loss: 1.0477 - acc: 0.4669\n",
      "Epoch 4/10\n",
      "182732/182732 [==============================] - 1710s 9ms/step - loss: 1.0456 - acc: 0.4692\n",
      "Epoch 5/10\n",
      "182732/182732 [==============================] - 1753s 10ms/step - loss: 1.0447 - acc: 0.4694\n",
      "Epoch 6/10\n",
      "182732/182732 [==============================] - 1768s 10ms/step - loss: 1.0439 - acc: 0.4706\n",
      "Epoch 7/10\n",
      "182732/182732 [==============================] - 1739s 10ms/step - loss: 1.0435 - acc: 0.4707\n",
      "Epoch 8/10\n",
      "182732/182732 [==============================] - 1723s 9ms/step - loss: 1.0432 - acc: 0.4712\n",
      "Epoch 9/10\n",
      "182732/182732 [==============================] - 1720s 9ms/step - loss: 1.0431 - acc: 0.4715\n",
      "Epoch 10/10\n",
      "182732/182732 [==============================] - 1710s 9ms/step - loss: 1.0431 - acc: 0.4716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ad083ba320>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model_3l.fit(train_dataset_batched, steps_per_epoch=train_size // batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_value(deep_model_3l.optimizer.lr, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "182732/182732 [==============================] - 1758s 10ms/step - loss: 1.0398 - acc: 0.4755\n",
      "Epoch 2/20\n",
      "182732/182732 [==============================] - 1712s 9ms/step - loss: 1.0396 - acc: 0.4759\n",
      "Epoch 3/20\n",
      "182732/182732 [==============================] - 1736s 10ms/step - loss: 1.0395 - acc: 0.4755\n",
      "Epoch 4/20\n",
      "182732/182732 [==============================] - 1748s 10ms/step - loss: 1.0392 - acc: 0.4763\n",
      "Epoch 5/20\n",
      "182732/182732 [==============================] - 1736s 10ms/step - loss: 1.0392 - acc: 0.4766\n",
      "Epoch 6/20\n",
      "182732/182732 [==============================] - 1746s 10ms/step - loss: 1.0390 - acc: 0.4762\n",
      "Epoch 7/20\n",
      "182732/182732 [==============================] - 1737s 10ms/step - loss: 1.0391 - acc: 0.4763\n",
      "Epoch 8/20\n",
      "182732/182732 [==============================] - 1746s 10ms/step - loss: 1.0389 - acc: 0.4766\n",
      "Epoch 9/20\n",
      "182732/182732 [==============================] - 1739s 10ms/step - loss: 1.0390 - acc: 0.4765\n",
      "Epoch 10/20\n",
      "182732/182732 [==============================] - 1740s 10ms/step - loss: 1.0390 - acc: 0.4765\n",
      "Epoch 11/20\n",
      "182732/182732 [==============================] - 1741s 10ms/step - loss: 1.0389 - acc: 0.4768\n",
      "Epoch 12/20\n",
      "182732/182732 [==============================] - 1740s 10ms/step - loss: 1.0387 - acc: 0.4770\n",
      "Epoch 13/20\n",
      "182732/182732 [==============================] - 1740s 10ms/step - loss: 1.0388 - acc: 0.4769\n",
      "Epoch 14/20\n",
      "182732/182732 [==============================] - 1741s 10ms/step - loss: 1.0387 - acc: 0.4770\n",
      "Epoch 15/20\n",
      "182732/182732 [==============================] - 1740s 10ms/step - loss: 1.0387 - acc: 0.4766\n",
      "Epoch 16/20\n",
      "182732/182732 [==============================] - 1742s 10ms/step - loss: 1.0386 - acc: 0.4768\n",
      "Epoch 17/20\n",
      "182732/182732 [==============================] - 1737s 10ms/step - loss: 1.0386 - acc: 0.4767\n",
      "Epoch 18/20\n",
      "182732/182732 [==============================] - 1740s 10ms/step - loss: 1.0386 - acc: 0.4768\n",
      "Epoch 19/20\n",
      "182732/182732 [==============================] - 1740s 10ms/step - loss: 1.0386 - acc: 0.4770\n",
      "Epoch 20/20\n",
      "182732/182732 [==============================] - 1739s 10ms/step - loss: 1.0385 - acc: 0.4769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ad18b6dda0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model_3l.fit(train_dataset_batched, steps_per_epoch=train_size // batch_size, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_value(deep_model_3l.optimizer.lr, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 86403/182732 [=============>................] - ETA: 14:43 - loss: 1.0810 - acc: 0.4032"
     ]
    }
   ],
   "source": [
    "deep_model_3l.fit(train_dataset_batched, steps_per_epoch=train_size // batch_size, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_3l.save_weights(\"deep_3l_s10_softsign_moresim.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 12s 6ms/step - loss: 1.0929 - acc: 0.3873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0928817737363279, 0.3873162]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model_3l.evaluate(dev_dataset.batch(batch_size), steps=dev_size // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
